# Kyle Kentner
# Dr. Doug Heisterkamp
# CS-5723: Artificial Intelligence
# 2 May 2022
# Image Sharpening via Reinforcement Learning
##################################################################################
# This file is the main driver file. It has some helper functions for the RL Model
# as well as some deprecated functions from the original CSP methodology.
# For a full implementation of the CSP method, see main_old_method.py.
##################################################################################

import Kentner_PA2 as kpa
import Kentner_Project_Util as kpu
import sys, getopt
import os
import cv2
import numpy as np
#from matplotlib import pyplot as plt

# For reinforcement-learning (OpenAI Gym and Keras)
import Sharpen_Env_Setup as ses
import gym
import random
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Flatten
from tensorflow.keras.optimizers import Adam
from rl.agents import DQNAgent
from rl.policy import BoltzmannQPolicy
from rl.memory import SequentialMemory

# Suppress Tensorflow deprecation warnings
import warnings
warnings.filterwarnings('ignore')
import logging
logger = logging.getLogger()
logger.disabled = True

# warnings.filterwarnings('ignore', category=DeprecationWarning)
# warnings.filterwarnings('ignore', category=FutureWarning)

# Build a deep-learning model using Keras
def build_model(states, actions):
    # Instantiate a Sequential model
    model = Sequential()

    # Add the states as a single, flat node
    #model.add(Flatten(input_shape=(1,states)))

    # Dense nodes with a relu activation function
    model.add(Dense(24, activation='relu', input_shape=states))
    model.add(Dense(24, activation='relu'))

    # Dense node with actions
    model.add(Dense(actions, activation='linear'))

    return model

# Build a reinforcement-learning agent using the deep-learning model and actions
def build_agent(model, actions):
    # Set up the policy and memory
    policy = BoltzmannQPolicy()
    memory = SequentialMemory(limit=50000, window_length=1)

    # Create the agent using the deep-learning model
    dqn = DQNAgent(model=model, memory=memory, policy=policy, nb_actions=actions, nb_steps_warmup=10,
                   target_model_update=1e-2)

    return dqn


# Main function
def main(argv, argc, preprocessing=False):
    logger.disabled = False
    print(argv)
    
    # Get the filename from the command line
    file_name = ''
    sharp_name = ''
    try:
        # If this is training data, a pair of filenames should be provided
        if argc > 1:
            # Get the command-line arguments as strings
            file_name = str(argv[1])
            
            # Check if a sharp "target" image was included
            if argc > 2:
                sharp_name = str(argv[2])
            
    except:
        print('ERROR: Make sure that the filename for the image was passed as a command-line argument')
        return 1
    
    # Check if file_name was initialized
    if file_name == '':
        print('ERROR: Filename not initialized')
        return 2
    else:
        print('Filename:', file_name)
    
    # For testing the naive FFT
    #img_color = kpu.FFT_Test(file_name, 19)
    #cv2.imwrite('IMG_OUT.jpg', img_color)
    #return 0
    
    # For using preprocessing techniques
    if preprocessing:
        '''
        Test Blur
        # Define a kernel to use for the blur
        kernel = init_kernel()
        
        # Get the input image
        img_original = cv2.imread(file_name)
        rows, columns, rgb = img_original.shape
        
        # Get the output (blurry) image and write
        img_new = gaussian_blur(img_original, rows, columns, kernel)
        cv2.imwrite(file_name[:len(file_name) - 4] + '_Blur.png', img_new)
        '''
        
        # Test MSE
        if file_name != '' and sharp_name != '':
            img_blurry = cv2.imread(file_name, 0)
            img_sharp = cv2.imread(sharp_name, 0)
            print(kpu.MSE(img_sharp, img_blurry))
        
        return 0
    
    # Get the initial color image
    img_blurry = cv2.imread(file_name, -1)
    
    # Set up the problem (environment, states, and actions)
    env = ses.SharpenEnv(file_name, img_blurry, sharp_name)
    states = env.observation_space.shape
    actions = env.action_space.n

    # Build the Reinforcement Learning Model using the problem
    model = build_model(states, actions)
    model.summary()

    # Create the agent
    dqn = build_agent(model, actions)
    dqn.compile(Adam(lr=1e-3), metrics=['mae'])  # Mean absolute error
    
    if sharp_name != '':
        # Fit the agent
        dqn.load_weights('dqn_sharpen_weights.h5f')
        dqn.fit(env, nb_steps=10000, visualize=False, verbose=1)
        
        # Write the image generated by the training
        cv2.imwrite('IMG_Train.png', env.img_processed)
        
        # Save the agent
        dqn.save_weights('dqn_sharpen_weights.h5f', overwrite=True)
        
    else:
        # Test the agent
        dqn.load_weights('dqn_sharpen_weights.h5f')
        scores = dqn.test(env, nb_episodes=1, visualize=False)
        print(np.mean(scores.history['episode_reward']))
        
        # Write the image generated by the testing
        cv2.imwrite('IMG_Test.png', env.img_processed)


# Initialization for Gaussian blur kernel
def init_kernel(diam=3):
    kernel = np.zeros((diam, diam))
    for i in range(diam):
        for j in range(diam):
            if i != j or i != 1:
                kernel[i, j] = 3
            else:
                kernel[i, j] = 4
    
    return kernel


# Return a blurred version of an input image
# https://www.youtube.com/watch?v=C_zFhWdM4ic
def gaussian_blur(img_blur, R, C, kernel):
    # Set up an output image
    img_out = np.zeros(img_blur.shape, dtype=int)
    
    # Iterate over each pixel in the original image and apply blur
    for y in range(0, R):
        for x in range(0, C):
            # Reinitialize values
            pixels = kernel[1, 1]
            sum_b = int(img_blur[y, x][0] * pixels)
            sum_g = int(img_blur[y, x][1] * pixels)
            sum_r = int(img_blur[y, x][2] * pixels)
            room_L = False
            room_R = False
            room_U = False
            room_D = False
            
            # Left neighbor
            if x > 0:
                pixels += kernel[1, 0]
                room_L = True
                #print(img_blur[y, x - 1][0], img_blur[y, x - 1][1], img_blur[y, x - 1][2])
                sum_b += img_blur[y, x - 1][0] * kernel[1, 0]
                sum_g += img_blur[y, x - 1][1] * kernel[1, 0]
                sum_r += img_blur[y, x - 1][2] * kernel[1, 0]
            
            # Right neighbor
            if x < C - 1:
                pixels += kernel[1, 2]
                room_R = True
                sum_b += img_blur[y, x + 1][0] * kernel[1, 2]
                sum_g += img_blur[y, x + 1][1] * kernel[1, 2]
                sum_r += img_blur[y, x + 1][2] * kernel[1, 2]
            
            # Upper neighbor
            if y > 0:
                pixels += kernel[0, 1]
                room_U = True
                sum_b += img_blur[y - 1, x][0] * kernel[0, 1]
                sum_g += img_blur[y - 1, x][1] * kernel[0, 1]
                sum_r += img_blur[y - 1, x][2] * kernel[0, 1]
                
            # Lower neighbor
            if y < R - 1:
                pixels += kernel[2, 1]
                room_D = True
                sum_b += img_blur[y + 1, x][0] * kernel[2, 1]
                sum_g += img_blur[y + 1, x][1] * kernel[2, 1]
                sum_r += img_blur[y + 1, x][2] * kernel[2, 1]

            # Top-left neighbor
            if room_L and room_U:
                pixels += kernel[0, 0]
                sum_b += img_blur[y - 1, x - 1][0] * kernel[0, 0]
                sum_g += img_blur[y - 1, x - 1][1] * kernel[0, 0]
                sum_r += img_blur[y - 1, x - 1][2] * kernel[0, 0]

            # Bottom-left neighbor
            if room_L and room_D:
                pixels += kernel[2, 0]
                sum_b += img_blur[y + 1, x - 1][0] * kernel[2, 0]
                sum_g += img_blur[y + 1, x - 1][1] * kernel[2, 0]
                sum_r += img_blur[y + 1, x - 1][2] * kernel[2, 0]

            # Top-right neighbor
            if room_R and room_U:
                pixels += kernel[0, 2]
                sum_b += img_blur[y - 1, x + 1][0] * kernel[0, 2]
                sum_g += img_blur[y - 1, x + 1][1] * kernel[0, 2]
                sum_r += img_blur[y - 1, x + 1][2] * kernel[0, 2]

            # Bottom-right neighbor
            if room_R and room_D:
                pixels += kernel[2, 2]
                sum_b += img_blur[y + 1, x + 1][0] * kernel[2, 2]
                sum_g += img_blur[y + 1, x + 1][1] * kernel[2, 2]
                sum_r += img_blur[y + 1, x + 1][2] * kernel[2, 2]
            
            # Get the blurred RGB
            avg_b = int(sum_b / pixels)
            avg_g = int(sum_g / pixels)
            avg_r = int(sum_r / pixels)
            
            # Assign the blurred RGB to the corresponding pixel in img_out
            img_out[y, x][0] = avg_b
            img_out[y, x][1] = avg_g
            img_out[y, x][2] = avg_r
        
    return img_out


# Runs the main function
# https://www.tutorialspoint.com/python/python_command_line_arguments.htm
if __name__ == '__main__':
    # Pass all command-line arguments to main; add a True flag to blur an image
    if len(sys.argv) > 1:
        main(sys.argv, len(sys.argv))
    else:
        print('ERROR: Input filename expected as a command-line parameter')


# Deprecated function; used for following the edges found via FFT and applying RGB-based constraints
def DFS(root_y, root_x, visited, img_base, img_fft, thld, max_y, max_x):
    # Initialize a Node object with the root's information
    root_node = kpa.Node()
    root_node.location = [root_y, root_x]
    root_node.rgb = img_base[root_y, root_x]

    # Set up two stacks: One for exploration, and one for revisions
    stack_explore = []
    stack_revise = []

    # Get the start and end points for exploring neighbors (avoid out-of-bounds exception)
    neigh_min_y = root_y - 1 if root_y - 1 > -1 else root_y
    neigh_max_y = root_y + 1 if root_y + 1 < max_y else root_y
    neigh_min_x = root_x - 1 if root_x - 1 > -1 else root_x
    neigh_max_x = root_x + 1 if root_x + 1 < max_x else root_x

    # Add all bordering pixels to the root; explore edge pixels, and constrain on non-edge pixels
    i = neigh_min_y
    j = neigh_min_x
    while i < neigh_max_y:
        while j < neigh_max_x:
            # Skip the current root
            if i != root_y and j != root_x:
                # Separate the edge neighbors from the non-edge neighbors based on threshold thld
                if img_fft[i, j] > thld:
                    # Edge pixel
                    stack_explore.append([i, j])
                else:
                    # Non-edge pixel
                    stack_revise.append([i, j])

                # Edge or not, this pixel may be added to visited
                visited[i, j] = True

            # Next column
            j += 1

        # Next row
        i += 1

    k = 0
    skip = -1
    while k < len(stack_revise):
        cur_y, cur_x = stack_revise[k]
        if k != skip and compare_pixels(img_base[root_y, root_x], img_base[cur_y, cur_x], root_node.similarity_index):
            # Relax the similarity requirement (makes revisions less likely)
            root_node.similarity_index -= 0.05
            
        else:
            # No revisions; check next neighbor
            k += 1

    # After correcting this pixel, explore each of the edge-pixel neighbors using DFS
    # print(stack_explore)
    for neighbor in stack_explore:
        DFS(neighbor[0], neighbor[1], visited, img_base, img_fft, thld, max_y, max_x)
        
        
def compare_pixels(px1, px2, sim):
    changes = False
    mag_1 = (int(px1[0]) + int(px1[1]) + int(px1[2])) / 3
    mag_2 = (int(px2[0]) + int(px2[1]) + int(px2[2])) / 3

    if mag_1 < mag_2:
        changes = True
        px1[0] = px2[0]
        px1[1] = px2[1]
        px1[2] = px2[2]

    return changes